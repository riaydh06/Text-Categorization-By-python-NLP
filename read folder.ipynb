{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['claxton', 'hunting', 'first', 'major', 'medal', 'british', 'hurdler', 'sarah', 'claxton', 'confident', 'win', 'first', 'major', 'medal', 'next', 'european', 'indoor', 'championships', 'the', 'already', 'smashed', 'british', 'record', '60m', 'hurdles', 'twice', 'setting', 'new', 'mark', 'seconds', 'win', 'aaas', 'quite', 'said', 'take', 'race', 'long', 'keep', 'training', 'much', 'think', 'chance', 'claxton', 'won', 'national', '60m', 'hurdles', 'title', 'past', 'three', 'years', 'struggled', 'translate', 'domestic', 'success', 'international', 'athlete', 'owns', 'equal', 'time', 'world', 'and', 'last', 'birmingham', 'grand', 'claxton', 'left', 'european', 'medal', 'favourite', 'russian', 'irina', 'shevchenko', 'trailing', 'sixth', 'for', 'first', 'claxton', 'preparing', 'campaign', 'hurdles', 'could', 'explain', 'leap', 'previous', 'also', 'contested', 'long', 'jump', 'since', 'moving', 'colchester', 'london', 'claxton', 'see', 'new', 'training', 'regime', 'pays', 'dividends', 'european', 'indoors', 'take', 'place', 'could', 'run', 'worlds', 'sonia', 'indicated', 'would', 'like', 'participate', 'next', 'world', 'cross', 'country', 'championships', 'athletics', 'ireland', 'hinted', 'cobh', 'runner', 'may', 'included', 'official', 'event', 'france', 'provincial', 'teams', 'selected', 'last', 'nationals', 'santry', 'officially', 'announced', 'present', 'preparing', 'london', 'marathon', 'the', 'participation', 'currentily', 'training', 'base', 'would', 'boost', 'ireland', 'team', 'won', 'bronze', 'three', 'years', 'the', 'first', 'three', 'santry', 'last', 'jolene', 'maria', 'mccambridge', 'fionnualla', 'automatic', 'selections', 'likely', 'form', 'part', 'also', 'take', 'part', 'bupa', 'great', 'ireland', 'run', 'april', 'greene', 'sets', 'sights', 'world', 'title', 'maurice', 'greene', 'aims', 'wipe', 'pain', 'losing', 'olympic', '100m', 'title', 'athens', 'winning', 'fourth', 'world', 'championship', 'crown', 'settle', 'bronze', 'greece', 'behind', 'fellow', 'american', 'justin', 'gatlin', 'francis', 'obikwelu', 'really', 'hurts', 'look', 'lost', 'things', 'said', 'races', 'birmingham', 'never', 'going', 'happen', 'goal', 'going', 'win', 'greene', 'crossed', 'line', 'seconds', 'behind', 'won', 'seconds', 'one', 'closest', 'fastest', 'sprints', 'but', 'greene', 'believes', 'lost', 'race', 'title', 'won', 'race', 'conserving', 'francis', 'obikwelu', 'came', 'took', 'third', 'know', 'believe', 'put', 'lane', 'seven', 'final', 'lane', 'feel', 'anything', 'felt', 'like', 'running', 'believe', 'middle', 'race', 'would', 'able', 'react', 'people', 'came', 'ahead', 'greene', 'also', 'denied', 'olympic', 'gold', '4x100m', 'relay', 'could', 'catch', 'mark', 'final', 'the', 'kansas', 'star', 'set', 'norwich', 'union', 'grand', 'the', 'pair', 'contest', 'distance', 'greene', 'currently', 'holds', 'world', 'record', 'another', 'indoor', 'meeting', 'france', 'resuming', 'training', 'outdoor', 'season', 'task', 'recapturing', 'world', 'title', 'helsinki', 'greene', 'believes', 'gatlin', 'prove', 'biggest', 'threat', 'ambitions', 'but', 'also', 'admits', 'faces', 'one', 'rival', 'world', 'always', 'someone', 'else', 'think', 'coming', 'would', 'say', 'ato', 'young', 'greene', 'got', 'five', 'six', 'young', 'guys', 'coming', 'iaaf', 'launches', 'fight', 'drugs', 'the', 'iaaf', 'world', 'governing', 'body', 'met', 'coaches', 'athletes', 'fight', 'drugs', 'two', 'task', 'forces', 'set', 'examine', 'doping', 'nutrition', 'also', 'agreed', 'programme', 'issue', 'public', 'media', 'decided', 'change', 'things', 'forum', 'stakeholders', 'allowing', 'express', 'said', 'iaaf', 'everyone', 'together', 'gave', 'lot', 'food', 'about', 'people', 'attended', 'meeting', 'including', 'iaaf', 'chief', 'lamine', 'diack', 'namibian', 'athlete', 'frankie', 'member', 'happy', 'see', 'members', 'athletics', 'respond', 'positively', 'iaaf', 'call', 'sit', 'together', 'discuss', 'fight', 'said', 'leading', 'federation', 'field', 'duty', 'keep', 'sport', 'the', 'two', 'task', 'forces', 'report', 'back', 'iaaf', 'april', 'meeting', 'dibaba', 'breaks', 'world', 'record', 'tirunesh', 'dibaba', 'set', 'new', 'world', 'record', 'winning', 'boston', 'indoor', 'dibaba', 'won', 'minutes', 'seconds', 'erase', 'previous', 'world', 'indoor', 'mark', 'set', 'another', 'berhane', 'stuttgart', 'last', 'but', 'compatriot', 'kenenisa', 'record', 'hopes', 'dashed', 'miscounted', 'laps', 'staged', 'sprint', 'finish', 'lap', 'alistair', 'cragg', 'won', 'bekele', 'battled', 'second', 'want', 'sit', 'back', 'get', 'said', 'kept', 'the', 'plan', '500m', 'matter', 'bekele', 'made', 'mistake', 'the', 'race', 'carolina', 'olympic', 'heptathlon', 'jolanda', 'ceplak', 'winning', 'kluft', 'took', 'long', 'jump', 'ceplak', 'easily', 'won', '800m', 'isinbayeva', 'claims', 'new', 'world', 'best', 'pole', 'vaulter', 'yelena', 'isinbayeva', 'broke', 'indoor', 'world', 'record', 'clearing', 'metres', 'lievin', '12th', 'world', 'record', 'career', 'came', 'days', 'cleared', 'norwich', 'union', 'grand', 'prix', 'the', 'olympic', 'champion', 'went', 'attempt', 'meeting', 'france', 'failed', 'clear', 'former', 'olympic', '100m', 'champion', 'maurice', 'greene', 'could', 'finish', 'second', 'leonard', 'second', 'consecutive', 'defeat', 'hands', 'fellow', 'also', 'won', 'birmingham', 'last', 'ran', 'race', 'said', 'won', 'best', 'time', 'happy', 'even', 'know', 'maurice', 'long', 'way', 'peak', 'start']\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize,sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "from nltk.stem import PorterStemmer\n",
    "from collections import Counter\n",
    "from collections import defaultdict\n",
    "import os\n",
    "import os.path\n",
    "\n",
    "st=PorterStemmer()\n",
    "path = 'C:\\\\Users\\\\ret\\\\sport_2' \n",
    "files = os.listdir(path)\n",
    "\n",
    "files_txt = [i for i in files if i.endswith('.txt')]\n",
    "count={}\n",
    "count_all_words=0\n",
    "arr=[]\n",
    "\n",
    "for x in range(0,len(files_txt)):\n",
    "        MyFile=open(files_txt[x],'r')\n",
    "        for y in MyFile.read().split():\n",
    "            count_all_words+=1\n",
    "            narr = [y]\n",
    "            arr = arr + narr\n",
    "\n",
    "\n",
    "sum1=0\n",
    "#for i in range(0,len(a1)):\n",
    "#    sum1 = sum1 + int(a1[i])\n",
    "read_data=filter(str.isalnum,a) \n",
    "stop_words=set(stopwords.words(\"english\"))\n",
    "#filtered_sentence=[]word_list\n",
    "filtered_sentence=[w for w in read_data if not w in stop_words]\n",
    "\n",
    "save_path = 'C:\\\\Users\\\\ret'\n",
    "name_of_file = 'sports_corpus'\n",
    "completeName = os.path.join(save_path, name_of_file+\".txt\")         \n",
    "fh1 = open(completeName, \"w\")\n",
    "#fh1=open(\"file_corpus_sports.txt\",\"w\")\n",
    "#a=[]\n",
    "    \n",
    "filtered_sentence=[item.lower() for item in filtered_sentence]\n",
    "filtered_sentence=[x for x in filtered_sentence if not x.isdigit()]\n",
    "    \n",
    "    \n",
    "for words in filtered_sentence:\n",
    "    if ( len(words)==1 ) :\n",
    "        filtered_sentence.remove(words)\n",
    "for x in filtered_sentence:\n",
    "    if ( len(x)==2 ) :\n",
    "        filtered_sentence.remove(x)\n",
    "        \n",
    "for w in  filtered_sentence:\n",
    "    fh1.write(st.stem(w)+ ' ')\n",
    "print(filtered_sentence)    \n",
    "print(sum1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'a1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-cc774c9bbc09>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[0msum1\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m     \u001b[0msum1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msum1\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[0mread_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfilter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misalnum\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'a1' is not defined"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize,sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "from nltk.stem import PorterStemmer\n",
    "from collections import Counter\n",
    "from collections import defaultdict\n",
    "import os\n",
    "import os.path\n",
    "\n",
    "st=PorterStemmer()\n",
    "path = 'C:\\\\Users\\\\ret\\\\sport_2' \n",
    "files = os.listdir(path)\n",
    "os.chdir(path)\n",
    "files_txt = [i for i in files if i.endswith('.txt')]\n",
    "a=[]\n",
    "print (len(files_txt))\n",
    "for x in range(0,len(files_txt)):\n",
    "        MyFile=open(files_txt[x],'r')\n",
    "        for y in MyFile.read().split():\n",
    "            a+=[y]\n",
    "\n",
    "sum1=0\n",
    "for i in range(0,len(a1)):\n",
    "    sum1 = sum1 + int(a1[i])\n",
    "read_data=filter(str.isalnum,a) \n",
    "stop_words=set(stopwords.words(\"english\"))\n",
    "#filtered_sentence=[]word_list\n",
    "filtered_sentence=[w for w in read_data if not w in stop_words]\n",
    "\n",
    "save_path = 'C:\\\\Users\\\\ret'\n",
    "name_of_file = 'sports_corpus'\n",
    "completeName = os.path.join(save_path, name_of_file+\".txt\")         \n",
    "fh1 = open(completeName, \"w\")\n",
    "#fh1=open(\"file_corpus_sports.txt\",\"w\")\n",
    "#a=[]\n",
    "    \n",
    "filtered_sentence=[item.lower() for item in filtered_sentence]\n",
    "filtered_sentence=[x for x in filtered_sentence if not x.isdigit()]\n",
    "    \n",
    "    \n",
    "for words in filtered_sentence:\n",
    "    if ( len(words)==1 ) :\n",
    "        filtered_sentence.remove(words)\n",
    "for x in filtered_sentence:\n",
    "    if ( len(x)==2 ) :\n",
    "        filtered_sentence.remove(x)\n",
    "        \n",
    "for w in  filtered_sentence:\n",
    "    fh1.write(st.stem(w)+ ' ')\n",
    "print(len(filtered_sentence) )   \n",
    "print(sum1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'S007.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-a0f3399e5578>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiles_txt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m         \u001b[0mMyFile\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiles_txt\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0my\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mMyFile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m             \u001b[0mcount_all_words\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'S007.txt'"
     ]
    }
   ],
   "source": [
    "\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize,sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "from nltk.stem import PorterStemmer\n",
    "from collections import Counter\n",
    "from collections import defaultdict\n",
    "import os\n",
    "import os.path\n",
    "\n",
    "st=PorterStemmer()\n",
    "path = 'C:\\\\Users\\\\ret\\\\sport_2' \n",
    "files = os.listdir(path)\n",
    "\n",
    "files_txt = [i for i in files if i.endswith('.txt')]\n",
    "count={}\n",
    "count_all_words=0\n",
    "arr=[]\n",
    "\n",
    "for x in range(0,len(files_txt)):\n",
    "        MyFile=open(files_txt[x],'r')\n",
    "        for y in MyFile.read().split():\n",
    "            count_all_words+=1\n",
    "            narr = [y]\n",
    "            arr = arr + narr\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
